"""
AI Study Monitor - College Mini Project
=======================================

This project implements a real-time study monitoring system using computer vision.
It detects student faces and mobile phones to monitor study sessions and alert
when distractions occur.

Features:
- Face detection using OpenCV Haar Cascades
- Phone detection using YOLOv8
- Audio alerts when phone detected while face is visible
- Real-time monitoring interface
- Distraction logging and reporting
- Demo mode for testing without webcam

Author: [Your Name]
Date: January 2026
"""

import cv2
import numpy as np
from datetime import datetime
import pygame
import time
import os
import sys
from ultralytics import YOLO

class WebcamHandler:
    """Handles webcam initialization and frame capture with robust error handling"""
    
    def __init__(self):
        self.cap = None
        self.camera_index = -1
        self.backend = cv2.CAP_DSHOW  # Use DirectShow backend for Windows stability
        self.is_initialized = False
        
    def initialize_camera(self):
        """
        Initialize webcam with comprehensive error handling and auto-detection
        
        Returns:
            bool: True if camera successfully initialized, False otherwise
        """
        print("üîç Searching for available webcam...")
        
        # Try different camera indices with DirectShow backend
        for index in range(5):  # Check indices 0-4
            try:
                print(f"  Testing camera index {index}...")
                
                # Try with DirectShow backend first (more stable on Windows)
                cap = cv2.VideoCapture(index, self.backend)
                
                if not cap.isOpened():
                    # Fallback to default backend if DirectShow fails
                    print(f"    DirectShow failed for index {index}, trying default backend...")
                    cap = cv2.VideoCapture(index)
                
                if cap.isOpened():
                    # Test if camera can actually capture frames
                    ret, test_frame = cap.read()
                    if ret and test_frame is not None:
                        # Verify frame properties
                        height, width = test_frame.shape[:2]
                        if width > 0 and height > 0:
                            self.cap = cap
                            self.camera_index = index
                            self.is_initialized = True
                            
                            print(f"‚úÖ Webcam successfully initialized!")
                            print(f"   Index: {index}")
                            print(f"   Resolution: {width}x{height}")
                            print(f"   Backend: {self._get_backend_name()}")
                            return True
                        else:
                            print(f"    Invalid frame dimensions: {width}x{height}")
                    else:
                        print(f"    Cannot capture test frame from index {index}")
                    
                    cap.release()  # Clean up failed attempt
                else:
                    print(f"    Camera index {index} not available")
                    
            except Exception as e:
                print(f"    Error testing camera index {index}: {str(e)}")
                continue
        
        # If no camera found, provide detailed troubleshooting
        self._show_camera_troubleshooting()
        return False
    
    def _get_backend_name(self):
        """Get human-readable backend name"""
        if self.backend == cv2.CAP_DSHOW:
            return "DirectShow (Windows)"
        elif self.backend == cv2.CAP_MSMF:
            return "Media Foundation (Windows)"
        else:
            return "Default"
    
    def _show_camera_troubleshooting(self):
        """Display comprehensive troubleshooting guide"""
        print("\n‚ùå No webcam detected!")
        print("\nüîß Troubleshooting Steps:")
        print("1. Check Physical Connection:")
        print("   ‚Ä¢ Ensure webcam is plugged in (USB)")
        print("   ‚Ä¢ Try different USB ports")
        print("   ‚Ä¢ Restart your computer")
        print("")
        print("2. Check Permissions:")
        print("   ‚Ä¢ Go to Settings > Privacy & security > Camera")
        print("   ‚Ä¢ Ensure camera access is enabled")
        print("   ‚Ä¢ Allow apps to access your camera")
        print("")
        print("3. Check for Conflicts:")
        print("   ‚Ä¢ Close other apps using camera (Zoom, Teams, browsers)")
        print("   ‚Ä¢ Check Device Manager for camera status")
        print("   ‚Ä¢ Update webcam drivers if needed")
        print("")
        print("4. Alternative Solutions:")
        print("   ‚Ä¢ Try running as Administrator")
        print("   ‚Ä¢ Test with different camera software")
        print("   ‚Ä¢ Use external webcam if available")
        print("")
        print("üí° For development/testing, you can run: python 'ai project.py' demo")
    
    def read_frame(self):
        """
        Read a frame from the webcam
        
        Returns:
            tuple: (success: bool, frame: numpy.ndarray or None)
        """
        if not self.is_initialized or self.cap is None:
            return False, None
            
        try:
            ret, frame = self.cap.read()
            if ret and frame is not None:
                return True, frame
            else:
                print("‚ö†Ô∏è  Warning: Failed to capture frame")
                return False, None
        except Exception as e:
            print(f"‚ö†Ô∏è  Warning: Error reading frame: {str(e)}")
            return False, None
    
    def get_camera_info(self):
        """
        Get information about the initialized camera
        
        Returns:
            dict: Camera information or None if not initialized
        """
        if not self.is_initialized:
            return None
            
        try:
            width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = self.cap.get(cv2.CAP_PROP_FPS)
            
            return {
                'index': self.camera_index,
                'resolution': f"{width}x{height}",
                'fps': fps,
                'backend': self._get_backend_name()
            }
        except Exception as e:
            print(f"‚ö†Ô∏è  Warning: Could not get camera info: {str(e)}")
            return None
    
    def release(self):
        """Properly release the webcam and clean up resources"""
        if self.cap is not None:
            try:
                self.cap.release()
                print("‚úì Webcam released successfully")
            except Exception as e:
                print(f"‚ö†Ô∏è  Warning: Error releasing webcam: {str(e)}")
            finally:
                self.cap = None
                self.is_initialized = False

class FaceDetector:
    """Handles face detection using OpenCV Haar Cascades"""
    
    def __init__(self):
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        if self.face_cascade.empty():
            raise ValueError("Error: Could not load face cascade classifier")
    
    def detect(self, frame):
        """Detect faces in the frame"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        # Optimized parameters for better detection
        faces = self.face_cascade.detectMultiScale(
            gray, 
            scaleFactor=1.05,  # Smaller for more detection
            minNeighbors=3,    # Lower for more sensitivity
            minSize=(30, 30)   # Minimum face size
        )
        
        # Draw rectangles and labels for detected faces
        for (x, y, w, h) in faces:
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.putText(frame, 'Face Detected', (x, y-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        return len(faces) > 0, frame

class PhoneDetector:
    """Handles mobile phone detection using YOLOv8"""
    
    def __init__(self):
        try:
            self.model = YOLO('yolov8n.pt')  # Load YOLOv8 nano model
            print("‚úì YOLO model loaded successfully")
        except Exception as e:
            raise ValueError(f"Error loading YOLO model: {e}")
    
    def detect(self, frame):
        """Detect phones in the frame"""
        phone_found = False
        
        try:
            results = self.model(frame, verbose=False, conf=0.5)  # Confidence threshold
            
            for result in results:
                boxes = result.boxes
                for box in boxes:
                    cls = int(box.cls[0])
                    conf = float(box.conf[0])
                    
                    # Class 67 is 'cell phone' in COCO dataset
                    if cls == 67 and conf > 0.5:
                        phone_found = True
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        
                        # Draw bounding box
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 3)
                        cv2.putText(frame, 'Phone Detected - Focus on Study', (x1, y1-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        except Exception as e:
            print(f"Warning: Phone detection error: {e}")
        
        return phone_found, frame

class AudioAlert:
    """Handles audio alert system with robust error handling and proper playback management"""

    def __init__(self):
        self.alert_sound = None
        self.current_channel = None
        self.last_alert_time = 0
        self.cooldown = 5  # seconds between alerts
        self.sound_duration = 1.5  # seconds - longer for better noticeability
        self.mixer_initialized = False
        self.sound_playing = False

        # Initialize pygame mixer with comprehensive error handling
        try:
            # Pre-initialize pygame if not already done
            if not pygame.get_init():
                pygame.init()

            # Initialize mixer with optimal settings for Windows
            pygame.mixer.init(frequency=44100, size=-16, channels=2, buffer=1024)
            self.mixer_initialized = True
            print("‚úì Audio system initialized successfully (44.1kHz, stereo)")

            # Set up channel for dedicated alert playback
            self.current_channel = pygame.mixer.Channel(0)  # Use channel 0 for alerts

        except Exception as e:
            print(f"‚ö†Ô∏è  Warning: Could not initialize audio system: {e}")
            print("   Audio alerts will be simulated with console messages")
            self.mixer_initialized = False

        # Try to load custom alert sound
        self._load_alert_sound()

    def _load_alert_sound(self):
        """Load alert sound with comprehensive error handling"""
        if not self.mixer_initialized:
            print("‚úì Audio alerts will use console notifications (mixer not available)")
            return

        # Try to load custom alert sound (WAV preferred)
        custom_sound_files = ['alert.wav', 'alert.WAV', 'alert.mp3', 'alert.ogg']

        for sound_file in custom_sound_files:
            if os.path.exists(sound_file):
                try:
                    self.alert_sound = pygame.mixer.Sound(sound_file)
                    print(f"‚úì Loaded custom alert sound: {sound_file}")
                    return
                except Exception as e:
                    print(f"‚ö†Ô∏è  Warning: Could not load {sound_file}: {e}")
                    continue

        # If no custom sound found, create default beep
        print("‚ÑπÔ∏è  No custom alert sound found, creating default beep...")
        self._create_default_sound()

    def _create_default_sound(self):
        """Create a reliable default beep sound"""
        if not self.mixer_initialized:
            print("‚úì Audio alerts will use console notifications (mixer not available)")
            return

        try:
            # Use higher quality settings for better sound
            sample_rate = 44100
            duration = self.sound_duration
            frequency = 1000  # Higher frequency for better audibility

            # Generate sine wave with fade in/out for smoother sound
            t = np.linspace(0, duration, int(sample_rate * duration))

            # Create fade envelope
            fade_samples = int(0.1 * sample_rate)  # 100ms fade
            fade_in = np.linspace(0, 1, fade_samples)
            fade_out = np.linspace(1, 0, fade_samples)
            sustain = np.ones(len(t) - 2 * fade_samples)

            envelope = np.concatenate([fade_in, sustain, fade_out])

            # Generate sine wave
            wave = np.sin(2 * np.pi * frequency * t) * envelope

            # Add some harmonics for richer sound
            wave += 0.3 * np.sin(2 * np.pi * frequency * 2 * t) * envelope

            # Normalize and convert to 16-bit
            wave = wave / np.max(np.abs(wave))  # Normalize
            wave = (wave * 32767).astype(np.int16)

            # Create stereo sound
            stereo_wave = np.column_stack((wave, wave))

            self.alert_sound = pygame.sndarray.make_sound(stereo_wave)
            print("‚úì Using default beep sound (add alert.wav for custom sound)")

        except Exception as e:
            print(f"‚ö†Ô∏è  Warning: Could not create default sound: {e}")
            print("   Audio alerts will use console notifications")
            self.alert_sound = None

    def play_alert(self, face_detected=False, require_face=True):
        """
        Play alert based on detection conditions.
        Manages sound playback to prevent overlapping and ensure completion.

        Args:
            face_detected (bool): Whether face is currently detected
            require_face (bool): Whether face detection is required to trigger alert
        """
        current_time = time.time()

        # Check if alert conditions are met
        conditions_met = False
        if require_face:
            # Original logic: require both face and cooldown
            conditions_met = face_detected and (current_time - self.last_alert_time) > self.cooldown
        else:
            # New logic: only require cooldown (for phone-only alerts)
            conditions_met = (current_time - self.last_alert_time) > self.cooldown

        if not conditions_met:
            return False

        # Check if sound is already playing
        if self.sound_playing:
            return False

        self.last_alert_time = current_time

        # Try to play actual sound
        if self.mixer_initialized and self.alert_sound is not None and self.current_channel is not None:
            try:
                # Stop any currently playing sound on this channel
                if self.current_channel.get_busy():
                    self.current_channel.stop()

                # Play the sound and mark as playing
                self.current_channel.play(self.alert_sound)
                self.sound_playing = True

                if require_face:
                    print(f"üîä ALERT: Phone detected while face visible at {datetime.now().strftime('%H:%M:%S')}")
                else:
                    print(f"üîä ALERT: Phone detected at {datetime.now().strftime('%H:%M:%S')}")
                return True

            except Exception as e:
                print(f"‚ö†Ô∏è  Warning: Could not play audio alert: {e}")
                if require_face:
                    print(f"üîä ALERT: Phone detected while face visible at {datetime.now().strftime('%H:%M:%S')} (console notification)")
                else:
                    print(f"üîä ALERT: Phone detected at {datetime.now().strftime('%H:%M:%S')} (console notification)")
                self.sound_playing = False
        else:
            # Fallback to console notification
            if require_face:
                print(f"üîä ALERT: Phone detected while face visible at {datetime.now().strftime('%H:%M:%S')} (console notification)")
            else:
                print(f"üîä ALERT: Phone detected at {datetime.now().strftime('%H:%M:%S')} (console notification)")

        return False

    def play_phone_alert(self):
        """
        Play alert when phone is detected (no face requirement).
        This is the new method for phone-only detection alerts.
        """
        return self.play_alert(face_detected=False, require_face=False)

    def update(self):
        """Update method to be called in main loop to handle sound completion"""
        # Check if sound has finished playing
        if self.sound_playing and self.current_channel:
            if not self.current_channel.get_busy():
                self.sound_playing = False

    def test_audio(self):
        """Test audio functionality with comprehensive diagnostics"""
        print("\nüîä Testing Audio System...")

        if not self.mixer_initialized:
            print("‚ùå Audio mixer not initialized")
            print("   Possible causes:")
            print("   - pygame not installed: pip install pygame")
            print("   - Audio drivers not available")
            print("   - System audio disabled")
            return False

        if self.alert_sound is None:
            print("‚ùå No alert sound available")
            print("   The system should have created a default beep sound")
            return False

        if self.current_channel is None:
            print("‚ùå No audio channel available")
            return False

        try:
            print("‚ñ∂Ô∏è  Playing test sound...")
            print(f"   Sound duration: {self.sound_duration}s")
            print(f"   Mixer initialized: {self.mixer_initialized}")
            print(f"   Channel available: {self.current_channel is not None}")

            # Stop any currently playing sound
            if self.current_channel.get_busy():
                self.current_channel.stop()

            # Play test sound
            self.current_channel.play(self.alert_sound)
            self.sound_playing = True

            # Wait for sound to finish with timeout
            start_time = time.time()
            while self.current_channel.get_busy() and (time.time() - start_time) < 3.0:
                pygame.time.wait(100)

            self.sound_playing = False

            if time.time() - start_time >= 3.0:
                print("‚ö†Ô∏è  Warning: Sound may not have completed properly")
            else:
                print("‚úÖ Audio test successful!")

            return True

        except Exception as e:
            print(f"‚ùå Audio test failed: {e}")
            print("   Detailed error information:")
            import traceback
            traceback.print_exc()
            return False

    def force_stop(self):
        """Force stop any currently playing alert sound"""
        if self.current_channel:
            try:
                self.current_channel.stop()
                self.sound_playing = False
                print("‚úì Audio alert stopped")
            except Exception as e:
                print(f"‚ö†Ô∏è  Warning: Could not stop audio: {e}")

class DistractionLogger:
    """Handles logging of distraction events"""
    
    def __init__(self):
        self.distraction_log = []
        self.phone_detection_start = None
        self.total_distraction_time = 0
    
    def start_distraction(self, timestamp):
        """Mark start of distraction period"""
        if self.phone_detection_start is None:
            self.phone_detection_start = timestamp
    
    def end_distraction(self, timestamp):
        """Mark end of distraction period and log it"""
        if self.phone_detection_start:
            duration = timestamp - self.phone_detection_start
            self.distraction_log.append({
                'start': datetime.fromtimestamp(self.phone_detection_start).strftime('%H:%M:%S'),
                'end': datetime.fromtimestamp(timestamp).strftime('%H:%M:%S'),
                'duration': duration
            })
            self.total_distraction_time += duration
            self.phone_detection_start = None
    
    def save_report(self):
        """Save distraction report to file"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'study_report_{timestamp}.txt'
        
        try:
            with open(filename, 'w') as f:
                f.write("="*60 + "\n")
                f.write("AI STUDY MONITOR - SESSION REPORT\n")
                f.write("="*60 + "\n\n")
                f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write(f"Total Distractions: {len(self.distraction_log)}\n")
                f.write(f"Total Distraction Time: {int(self.total_distraction_time)} seconds\n")
                
                if self.distraction_log:
                    avg_time = self.total_distraction_time / len(self.distraction_log)
                    f.write(f"Average Distraction Duration: {avg_time:.1f} seconds\n\n")
                    
                    f.write("Distraction Details:\n")
                    f.write("-"*60 + "\n")
                    for i, log in enumerate(self.distraction_log, 1):
                        f.write(f"{i}. Start: {log['start']} | End: {log['end']} | Duration: {log['duration']:.1f}s\n")
                else:
                    f.write("No distractions recorded - Great focus!\n")
                
                f.write("\n" + "="*60 + "\n")
            
            print(f"‚úì Report saved: {filename}")
            return filename
        
        except Exception as e:
            print(f"Error saving report: {e}")
            return None

class StudyMonitorUI:
    """Handles the monitoring interface display"""
    
    def __init__(self):
        self.warning_display_time = 0
    
    def draw_interface(self, frame, face_detected, phone_detected, distraction_logger):
        """Draw the monitoring interface overlay"""
        h, w = frame.shape[:2]
        
        # Semi-transparent overlay for stats
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (450, 200), (0, 0, 0), -1)
        frame = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)
        
        # Title
        cv2.putText(frame, 'AI Study Monitor', (20, 40),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        # Status indicators
        face_status = "‚úì Detected" if face_detected else "‚úó Not Detected"
        face_color = (0, 255, 0) if face_detected else (0, 0, 255)
        cv2.putText(frame, f'Face: {face_status}', (20, 75),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, face_color, 2)
        
        phone_status = "‚úó Clear" if not phone_detected else "‚ö† DETECTED!"
        phone_color = (0, 255, 0) if not phone_detected else (0, 0, 255)
        cv2.putText(frame, f'Phone: {phone_status}', (20, 105),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, phone_color, 2)
        
        # Statistics
        cv2.putText(frame, f'Distractions: {len(distraction_logger.distraction_log)}', (20, 135),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(frame, f'Total Time: {int(distraction_logger.total_distraction_time)}s', (20, 160),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # Warning message when phone detected
        if phone_detected and time.time() - self.warning_display_time < 3:
            warning = "PUT AWAY YOUR PHONE!"
            text_size = cv2.getTextSize(warning, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)[0]
            text_x = (w - text_size[0]) // 2
            text_y = h - 50
            
            # Warning background
            cv2.rectangle(frame, (text_x-10, text_y-text_size[1]-10),
                         (text_x+text_size[0]+10, text_y+10), (0, 0, 255), -1)
            cv2.putText(frame, warning, (text_x, text_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
        
        # Instructions
        cv2.putText(frame, 'Press Q to quit | S to save report', (10, h-20),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
        
        return frame

class StudyMonitor:
    """
    Main Study Monitor class that coordinates all components
    
    This class implements a computer vision system for monitoring study sessions.
    It uses separate components for webcam handling, face detection, phone detection,
    audio alerts, and logging to maintain clean separation of concerns.
    """
    
    def __init__(self):
        """Initialize all components with error handling"""
        try:
            print("Initializing AI Study Monitor...")
            
            # Initialize components
            self.webcam = WebcamHandler()
            self.face_detector = FaceDetector()
            self.phone_detector = PhoneDetector()
            self.audio_alert = AudioAlert()
            self.logger = DistractionLogger()
            self.ui = StudyMonitorUI()
            
            # Tracking variables
            self.phone_detected = False
            self.frame_count = 0
            
            print("‚úì All components initialized successfully")
            
            # Test audio system
            self.audio_alert.test_audio()
            
        except Exception as e:
            print(f"‚ùå Initialization error: {e}")
            raise
    
    def run_monitoring(self):
        """Main monitoring loop with improved error handling"""
        print("\n" + "="*60)
        print("AI STUDY MONITORING SYSTEM")
        print("="*60)
        
        # Initialize webcam with robust error handling
        if not self.webcam.initialize_camera():
            print("\nüí° Tip: Run 'python \"ai project.py\" demo' for testing without camera")
            return
        
        # Get and display camera information
        camera_info = self.webcam.get_camera_info()
        if camera_info:
            print(f"\nüìπ Camera Details:")
            print(f"   Resolution: {camera_info['resolution']}")
            print(f"   FPS: {camera_info['fps']:.1f}")
        
        print("\nüéØ Monitoring active...")
        print("- Face detection: ENABLED")
        print("- Phone detection: ENABLED") 
        print("- Audio alerts: ENABLED (only when face + phone detected)")
        print("\nControls: Q=Quit | S=Save Report\n")
        
        try:
            while True:
                # Read frame with error handling
                ret, frame = self.webcam.read_frame()
                if not ret or frame is None:
                    print("‚ùå ERROR: Lost camera connection!")
                    print("Please check your webcam connection.")
                    break
                
                self.frame_count += 1
                
                # Apply mirror effect for natural viewing
                frame = cv2.flip(frame, 1)
                
                # Detect face and phone with error handling
                try:
                    face_detected, frame = self.face_detector.detect(frame)
                except Exception as e:
                    print(f"‚ö†Ô∏è  Face detection error: {e}")
                    face_detected = False
                
                try:
                    phone_detected_now, frame = self.phone_detector.detect(frame)
                except Exception as e:
                    print(f"‚ö†Ô∏è  Phone detection error: {e}")
                    phone_detected_now = False
                
                # Handle phone detection state changes
                if phone_detected_now and not self.phone_detected:
                    # Phone just appeared - trigger alert immediately
                    self.phone_detected = True
                    self.logger.start_distraction(time.time())
                    
                    # Play alert when phone is detected (no face requirement needed)
                    self.audio_alert.play_phone_alert()
                    self.ui.warning_display_time = time.time()
                    
                elif not phone_detected_now and self.phone_detected:
                    # Phone removed - end distraction
                    self.phone_detected = False
                    self.logger.end_distraction(time.time())
                
                # Update audio system to handle sound completion
                self.audio_alert.update()
                
                # Draw interface
                frame = self.ui.draw_interface(frame, face_detected, self.phone_detected, self.logger)
                
                # Display frame
                cv2.imshow('AI Study Monitor', frame)
                
                # Handle keyboard input
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q') or key == ord('Q'):
                    print("\n‚èπÔ∏è Shutting down monitoring...")
                    break
                elif key == ord('s') or key == ord('S'):
                    self.logger.save_report()
        
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è Monitoring stopped by user (Ctrl+C)")
        except Exception as e:
            print(f"\n‚ùå Unexpected error during monitoring: {e}")
        finally:
            # Ensure proper cleanup
            if self.phone_detected and self.logger.phone_detection_start:
                self.logger.end_distraction(time.time())
            
            self.webcam.release()
            cv2.destroyAllWindows()
            
            # Final report
            print("\n" + "="*60)
            print("SESSION SUMMARY")
            print("="*60)
            print(f"Total frames processed: {self.frame_count}")
            print(f"Total distractions: {len(self.logger.distraction_log)}")
            print(f"Total distraction time: {int(self.logger.total_distraction_time)} seconds")
            
            # Auto-save final report
            filename = self.logger.save_report()
            if filename:
                print(f"\nüìÑ Final report saved to: {filename}")
            print("\nüôè Thank you for using AI Study Monitor!")

def main():
    """Main function with multiple mode support"""
    if len(sys.argv) > 1:
        mode = sys.argv[1].lower()
        
        if mode == 'test-audio':
            print("üîä AUDIO TEST MODE")
            print("Testing audio system independently...")
            
            try:
                audio_test = AudioAlert()
                success = audio_test.test_audio()
                if success:
                    print("\n‚úÖ Audio system is working correctly!")
                else:
                    print("\n‚ùå Audio system has issues - check pygame installation and sound settings")
            except Exception as e:
                print(f"\n‚ùå Audio test failed with error: {e}")
            return
        
        elif mode == 'demo':
            print("üéÆ DEMO MODE - Testing without webcam")
            print("This mode simulates the monitoring interface for development/testing")
            print("\nDemo features:")
            print("- Simulated face and phone detection")
            print("- Working audio alerts")
            print("- Report generation")
            print("- All UI elements")
            print("\nPress Q to quit | S to save report | P to simulate phone detection")
            
            # Initialize audio system for demo
            demo_audio = AudioAlert()
            
            # Simple demo implementation
            demo_frame = np.zeros((480, 640, 3), dtype=np.uint8)
            frame_count = 0
            phone_detected = False
            
            try:
                while True:
                    frame_count += 1
                    face_detected = np.random.random() > 0.1  # 90% face detection
                    
                    # Simulate occasional phone detection
                    phone_detected_now = np.random.random() > 0.95
                    
                    if phone_detected_now and not phone_detected:
                        phone_detected = True
                        print("üé≠ DEMO: Phone detected!")
                        # Use actual audio alert system
                        demo_audio.play_phone_alert()
                    elif not phone_detected_now and phone_detected:
                        phone_detected = False
                    
                    # Update audio system
                    demo_audio.update()
                    
                    # Draw demo interface
                    demo_frame_copy = demo_frame.copy()
                    cv2.putText(demo_frame_copy, 'AI Study Monitor - DEMO MODE', (20, 40),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                    
                    face_status = "‚úì Detected" if face_detected else "‚úó Not Detected"
                    face_color = (0, 255, 0) if face_detected else (0, 0, 255)
                    cv2.putText(demo_frame_copy, f'Face: {face_status}', (20, 75),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, face_color, 2)
                    
                    phone_status = "‚úó Clear" if not phone_detected else "‚ö† DETECTED!"
                    phone_color = (0, 255, 0) if not phone_detected else (0, 0, 255)
                    cv2.putText(demo_frame_copy, f'Phone: {phone_status}', (20, 105),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, phone_color, 2)
                    
                    cv2.putText(demo_frame_copy, f'Frames: {frame_count}', (20, 135),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                    
                    cv2.putText(demo_frame_copy, 'Press Q to quit | S to save report', (10, 470),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
                    
                    cv2.imshow('AI Study Monitor - DEMO MODE', demo_frame_copy)
                    
                    key = cv2.waitKey(100) & 0xFF
                    if key == ord('q') or key == ord('Q'):
                        print("\n‚èπÔ∏è Demo ended by user")
                        break
                    elif key == ord('p') or key == ord('P'):
                        phone_detected = True
                        print("üé≠ MANUAL: Phone detection triggered!")
                        demo_audio.play_phone_alert()
            
            finally:
                cv2.destroyAllWindows()
                print("\nüéÆ Demo completed successfully!")
            return
    
    # Normal monitoring mode
    try:
        monitor = StudyMonitor()
        monitor.run_monitoring()
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Monitoring stopped by user (Ctrl+C)")
    except Exception as e:
        print(f"‚ùå Fatal error: {e}")
        print("Please check your setup and try again")
    
    try:
        monitor = StudyMonitor()
        monitor.run_monitoring()
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Monitoring stopped by user (Ctrl+C)")
    except Exception as e:
        print(f"‚ùå Fatal error: {e}")
        print("Please check your setup and try again")

if __name__ == "__main__":
    main()